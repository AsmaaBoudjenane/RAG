\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{logo_UD}{{\caption@xref {logo_UD}{ on input line 10}}{1}{}{figure.caption.1}{}}
\pgfsyspdfmark {pgfid1}{6749099}{47583362}
\citation{evidentlyai2025}
\citation{evidentlyai2025}
\citation{Ding2024}
\citation{zhang2021recsys}
\citation{kang2018selfat}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations }{}{chapter*.6}\protected@file@percent }
\citation{murugan2024nlp}
\@writefile{toc}{\contentsline {chapter}{General introduction}{1}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Large Language Models (LLMs)}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}\protected@file@percent }
\newlabel{start1}{{1.1}{1}{Introduction}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Natural language processing (NLP)}{1}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Historical development of NLP}{1}{subsection.1.2.1}\protected@file@percent }
\citation{techtarget_nlp}
\citation{murugan2024nlp}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The Vauquois triangle, illustrating the foundations of machine translation.}}{2}{figure.caption.7}\protected@file@percent }
\newlabel{the_historyOf_nlp.png}{{1.1}{2}{The Vauquois triangle, illustrating the foundations of machine translation}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Importance of natural language processing}{2}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Neural Networks in NLP}{2}{section.1.3}\protected@file@percent }
\citation{taylor2017neural}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Artificial Neural Network (ANN).}}{3}{figure.caption.8}\protected@file@percent }
\newlabel{ANN.png}{{1.2}{3}{Artificial Neural Network (ANN)}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Basics Concepts in Neural Networks}{3}{subsection.1.3.1}\protected@file@percent }
\citation{cho2014learning}
\citation{geeksforgeeks_lstm}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2} Recurrent Neural Networks (RNNs)}{4}{subsection.1.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces RNN Architecture.}}{4}{figure.caption.9}\protected@file@percent }
\newlabel{RNN.png}{{1.3}{4}{RNN Architecture}{figure.caption.9}{}}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3} Long-Short Term Memory (LSTM)}{5}{subsection.1.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces LSTM Architecture.}}{5}{figure.caption.10}\protected@file@percent }
\newlabel{/LSTM.png}{{1.4}{5}{LSTM Architecture}{figure.caption.10}{}}
\citation{rothman2021transformers}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {section}{\numberline {1.4} Transformer Architecture}{6}{section.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces The Transformer - model architecture..}}{6}{figure.caption.11}\protected@file@percent }
\newlabel{trasformers.png}{{1.5}{6}{The Transformer - model architecture.}{figure.caption.11}{}}
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Encoder and Decoder Stacks}{7}{subsection.1.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Encoder and Decoder Stacks}}{7}{figure.caption.12}\protected@file@percent }
\newlabel{incoderDecoder.png}{{1.6}{7}{Encoder and Decoder Stacks}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Self-Attention Mechanism}{7}{subsection.1.4.2}\protected@file@percent }
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\citation{alammar2018illustratedtransformer}
\citation{devlin2019bert}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Query, Key, and Value Vectors:}{8}{subsection.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Self-Attention Calculation:}{8}{subsection.1.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}Role of Multi-Head Attention}{8}{subsection.1.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.6}Positional Encoding:}{8}{subsection.1.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.7}Transformers in NLP}{8}{subsection.1.4.7}\protected@file@percent }
\citation{brown2020language}
\citation{touvron2023llama}
\@writefile{toc}{\contentsline {section}{\numberline {1.5} Emergence of Large Language Models (LLMs)}{9}{section.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Scaling in Large Language Models (LLMs)}{9}{subsection.1.5.1}\protected@file@percent }
\citation{wang2023language}
\citation{touvron2023llama}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Pre-training}{10}{subsection.1.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Training Tokenization in Full, Prefix, and Masked Language Modeling.}}{10}{figure.caption.13}\protected@file@percent }
\citation{brown2020language}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}Fine-tuning }{11}{subsection.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.4}Few-Shot, One-Shot, and Zero-Shot Learning}{11}{subsection.1.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.5}Evaluation Datasets and Tasks}{11}{subsection.1.5.5}\protected@file@percent }
\citation{Naveed2024}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Popular Models and Datasets}{12}{section.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}GPT-N Models}{12}{subsection.1.6.1}\protected@file@percent }
\citation{yenduri2023gpt}
\citation{devlin2019bert}
\citation{raffel2023exploring}
\citation{radford2019language}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.2}BERT}{13}{subsection.1.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.3}T5}{13}{subsection.1.6.3}\protected@file@percent }
\citation{helwe2024}
\citation{Naveed2024}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces exammple of RuleTaker dataset }}{14}{figure.caption.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.4}LLAMA2}{14}{subsection.1.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.5}WebText }{14}{subsection.1.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.6}RuleTaker}{14}{subsection.1.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Challenges and Limitations}{14}{section.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.1} Computational Cost}{15}{subsection.1.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.2}Overfitting}{15}{subsection.1.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.3} Interpretability and Explainability}{15}{subsection.1.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.4} Hallucinations}{15}{subsection.1.7.4}\protected@file@percent }
\citation{Naveed2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.5}Privacy Concerns}{16}{subsection.1.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.6}Real-Time Processing}{16}{subsection.1.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Domains of Application}{16}{section.1.8}\protected@file@percent }
\citation{helwe2024}
\citation{Naveed2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Law}{17}{subsection.1.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}Cybersecurity}{17}{subsection.1.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.3}Medicine}{17}{subsection.1.8.3}\protected@file@percent }
\citation{helwe2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.4}journalism}{18}{subsection.1.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Conclusion}{18}{section.1.9}\protected@file@percent }
\citation{selvaraj2024}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}RAG (Retrieval-Augmented Generation)}{19}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1} Introduction}{19}{section.2.1}\protected@file@percent }
\newlabel{start2}{{2.1}{19}{Introduction}{section.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Fundamentals of Retrieval-Augmented Generation}{19}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Definition of RAG}{19}{subsection.2.2.1}\protected@file@percent }
\citation{gao2024retrieval}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Historical Development of RAG}{20}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3} Differences Between RAG and Fine-Tuning}{20}{subsection.2.2.3}\protected@file@percent }
\citation{gao2024retrieval}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Types of RAG Systems}{21}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Naive RAG}{21}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Advanced RAG}{22}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.1}Pre-retrieval Strategies:}{22}{subsubsection.2.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.2}Post-Retrieval Strategies:}{22}{subsubsection.2.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Modular RAG}{23}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3.1}New Modules}{23}{subsubsection.2.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3.2}New Patterns}{23}{subsubsection.2.3.3.2}\protected@file@percent }
\citation{lewis2020retrieval}
\citation{karpukhin2020dense}
\citation{lewis2020retrieval}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Core Components of RAG}{24}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1} Retrieval Mechanism}{24}{subsection.2.4.1}\protected@file@percent }
\citation{mombaerts2024meta}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Generation Process}{25}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3} Augmentation Techniques}{25}{subsection.2.4.3}\protected@file@percent }
\citation{sbert2024}
\citation{zhou2020trustworthiness}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Rag architecture}}{26}{figure.caption.15}\protected@file@percent }
\newlabel{rag_architectur.png}{{2.1}{26}{Rag architecture}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Training and Fine-Tuning RAG Models}{26}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Training the Retriever}{26}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Task and Evaluation}{26}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Factuality}{27}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2} Robustness}{27}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Fairness}{27}{subsection.2.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Objective Metrics:}{27}{subsection.2.6.4}\protected@file@percent }
\citation{zhao2024retrieval}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.5}Subjective Metrics}{28}{subsection.2.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Limitations}{28}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Noisy Retrieval Results}{28}{subsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Extra Overhead}{28}{subsection.2.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Interaction of Retrieval and Generation}{29}{subsection.2.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.4}Long Context Generation:}{29}{subsection.2.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Conclusion}{30}{section.2.8}\protected@file@percent }
\citation{pareto2024rag}
\citation{Rossi_2024}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}k Selection in Retrieval}{31}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{31}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Defining k: The Number of Retrieved Documents}{31}{section.3.2}\protected@file@percent }
\citation{geeksforgeeks2022precision}
\citation{deconvoluteai2024metrics}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Basic retrieval}}{32}{figure.caption.16}\protected@file@percent }
\newlabel{rag_retrival.png}{{3.1}{32}{Basic retrieval}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Impact of k on Retrieval Performance}{32}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Recall vs. Precision}{32}{subsection.3.3.1}\protected@file@percent }
\citation{deconvoluteai2024metrics}
\citation{manning2008ir}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Retrieval Speed and Computational Cost}{33}{subsection.3.3.2}\protected@file@percent }
\citation{enwiki:1262179867}
\citation{evidentlyai2025}
\citation{evidentlyai2025}
\citation{evidentlyai2025}
\citation{evidentlyai2025}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Document Ranking Quality}{34}{subsection.3.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Precision in Document Ranking\cite  {evidentlyai2025}}}{34}{figure.caption.17}\protected@file@percent }
\newlabel{precisionR}{{3.2}{34}{Precision in Document Ranking\cite {evidentlyai2025}}{figure.caption.17}{}}
\citation{salemi2023evaluating}
\citation{wan2025cognitivealigneddocumentselectionretrievalaugmented}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Recall in Document Ranking\cite  {evidentlyai2025}}}{35}{figure.caption.18}\protected@file@percent }
\newlabel{recalR}{{3.3}{35}{Recall in Document Ranking\cite {evidentlyai2025}}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Impact of k on Generation Quality}{35}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Trade-off Between Diversity and Relevance}{35}{subsection.3.4.1}\protected@file@percent }
\citation{freitag-al-onaizan-2017-beam}
\citation{tensorrt_llm_beam_search}
\citation{zheng2024enhancing}
\citation{10.1561/1500000019}
\citation{gfg2025tfidf}
\citation{10.1007/978-3-030-72240-1_49}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Effect on Text Generation Models}{36}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Existing Solutions for k Selection}{36}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Static k Selection}{36}{subsection.3.5.1}\protected@file@percent }
\citation{karpukhin2020dense}
\citation{chen-etal-2024-dense}
\citation{enwiki:1276232158}
\citation{culpepper2016dynamictradeoffpredictionmultistage}
\citation{10.1007/978-3-319-70145-5_1}
\citation{sawarkar2024blendedragimprovingrag}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Dynamic k Selection}{37}{subsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Hybrid k Selection}{37}{subsection.3.5.3}\protected@file@percent }
\citation{zhu2024staykatehybridincontextexample}
\citation{Ding2024}
\citation{Ding2024}
\citation{zhai2023revisiting}
\citation{Ding2024}
\@writefile{toc}{\contentsline {section}{\numberline {3.6} Proposed Solution}{38}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Mixture of Logits (MoL)}{38}{subsection.3.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Mixture of Logits(MoL) learned similarity.\cite  {Ding2024}}}{38}{figure.caption.19}\protected@file@percent }
\newlabel{Mixture_of_Logits }{{3.4}{38}{Mixture of Logits(MoL) learned similarity.\cite {Ding2024}}{figure.caption.19}{}}
\citation{zhai2023revisiting}
\citation{zhai2023revisiting}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Algorithm Design}{39}{subsection.3.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces propused solution steps}}{40}{figure.caption.20}\protected@file@percent }
\newlabel{propused _solution_steps}{{3.5}{40}{propused solution steps}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Pseudocode}{40}{subsection.3.6.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Hybrid Exact Top-k with Threshold-Based k Selection}}{41}{algocf.1}\protected@file@percent }
\newlabel{ALgo1}{{1}{41}{Pseudocode}{algocf.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7} Conclusion }{42}{section.3.7}\protected@file@percent }
\citation{Roy2022}
\citation{5174476}
\citation{WANG201110831}
\citation{zhang2021recsys}
\citation{zhang2021recsys}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experimental Results}{43}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{43}{section.4.1}\protected@file@percent }
\newlabel{start6}{{4.1}{43}{Introduction}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Recommendation System Overview}{43}{section.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Recommendation System Process\cite  {zhang2021recsys}}}{43}{figure.caption.21}\protected@file@percent }
\newlabel{Recommendation_System _Process}{{4.1}{43}{Recommendation System Process\cite {zhang2021recsys}}{figure.caption.21}{}}
\citation{kang2018selfat}
\citation{kang2018selfat}
\citation{kang2018selfat}
\citation{Harper2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}SASRec: Self-Attentive Sequential Recommendation}{44}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}SASRec Model Architecture}{44}{subsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces the training process of SASRec\cite  {kang2018selfat}}}{44}{figure.caption.22}\protected@file@percent }
\newlabel{the_training_process_of_SASRec}{{4.2}{44}{the training process of SASRec\cite {kang2018selfat}}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3} Datasets}{45}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}MovieLens-100K}{45}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}MovieLens-1M}{45}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Experimental Setup}{45}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Hyperparameter Settings}{46}{subsection.4.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Results on 100kMovies dataset}}{46}{table.caption.23}\protected@file@percent }
\newlabel{tab:100k_movies}{{4.1}{46}{Results on 100kMovies dataset}{table.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Results on 1M Movies dataset}}{46}{table.caption.24}\protected@file@percent }
\newlabel{tab:1m_movies}{{4.2}{46}{Results on 1M Movies dataset}{table.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2} Impact of Hyperparameters}{46}{subsection.4.4.2}\protected@file@percent }
\citation{Tamm_2021}
\citation{eviden2025mrr}
\citation{Tamm_2021}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Evaluation Metrics}{47}{section.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Results and Analysis}{48}{section.4.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Performance Comparison of SASRec+Hybrid and SASRec+MoL on MovieLens 100K and 1M Datasets}}{48}{table.caption.25}\protected@file@percent }
\newlabel{tab:results_tab}{{4.3}{48}{Performance Comparison of SASRec+Hybrid and SASRec+MoL on MovieLens 100K and 1M Datasets}{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Discussion}{48}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Conclusion}{49}{section.4.7}\protected@file@percent }
\citation{*}
\bibstyle{unsrt}
\bibdata{Biblio}
\bibcite{evidentlyai2025}{1}
\bibcite{Ding2024}{2}
\bibcite{zhang2021recsys}{3}
\bibcite{kang2018selfat}{4}
\bibcite{murugan2024nlp}{5}
\bibcite{techtarget_nlp}{6}
\bibcite{taylor2017neural}{7}
\bibcite{cho2014learning}{8}
\bibcite{geeksforgeeks_lstm}{9}
\bibcite{hochreiter1997long}{10}
\bibcite{rothman2021transformers}{11}
\bibcite{vaswani2017attention}{12}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{50}{chapter*.26}\protected@file@percent }
\bibcite{alammar2018illustratedtransformer}{13}
\bibcite{devlin2019bert}{14}
\bibcite{brown2020language}{15}
\bibcite{touvron2023llama}{16}
\bibcite{wang2023language}{17}
\bibcite{Naveed2024}{18}
\bibcite{yenduri2023gpt}{19}
\bibcite{raffel2023exploring}{20}
\bibcite{radford2019language}{21}
\bibcite{helwe2024}{22}
\bibcite{selvaraj2024}{23}
\bibcite{gao2024retrieval}{24}
\bibcite{lewis2020retrieval}{25}
\bibcite{karpukhin2020dense}{26}
\bibcite{mombaerts2024meta}{27}
\bibcite{sbert2024}{28}
\bibcite{zhou2020trustworthiness}{29}
\bibcite{zhao2024retrieval}{30}
\bibcite{pareto2024rag}{31}
\bibcite{Rossi_2024}{32}
\bibcite{geeksforgeeks2022precision}{33}
\bibcite{deconvoluteai2024metrics}{34}
\bibcite{manning2008ir}{35}
\bibcite{enwiki:1262179867}{36}
\bibcite{salemi2023evaluating}{37}
\bibcite{wan2025cognitivealigneddocumentselectionretrievalaugmented}{38}
\bibcite{freitag-al-onaizan-2017-beam}{39}
\bibcite{tensorrt_llm_beam_search}{40}
\bibcite{zheng2024enhancing}{41}
\bibcite{10.1561/1500000019}{42}
\bibcite{gfg2025tfidf}{43}
\bibcite{10.1007/978-3-030-72240-1_49}{44}
\bibcite{chen-etal-2024-dense}{45}
\bibcite{enwiki:1276232158}{46}
\bibcite{culpepper2016dynamictradeoffpredictionmultistage}{47}
\bibcite{10.1007/978-3-319-70145-5_1}{48}
\bibcite{sawarkar2024blendedragimprovingrag}{49}
\bibcite{zhu2024staykatehybridincontextexample}{50}
\bibcite{zhai2023revisiting}{51}
\bibcite{Roy2022}{52}
\bibcite{5174476}{53}
\bibcite{WANG201110831}{54}
\bibcite{Harper2015}{55}
\bibcite{Tamm_2021}{56}
\bibcite{eviden2025mrr}{57}
\@input{Appendix_A.aux}
\@input{Appendix_B.aux}
\gdef \@abspage@last{70}
