\babel@toc {english}{}\relax 
\contentsline {chapter}{List of Figures}{}{chapter*.4}%
\contentsline {chapter}{List of Tables}{}{chapter*.5}%
\contentsline {chapter}{List of Abbreviations }{}{chapter*.6}%
\contentsline {chapter}{General introduction}{1}{chapter*.7}%
\contentsline {chapter}{\numberline {1}Large Language Models (LLMs)}{4}{chapter.1}%
\contentsline {section}{\numberline {1.1}Introduction}{4}{section.1.1}%
\contentsline {section}{\numberline {1.2}Natural language processing (NLP)}{4}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Historical development of (NLP)}{4}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Importance of natural language processing}{5}{subsection.1.2.2}%
\contentsline {section}{\numberline {1.3}Neural Networks in NLP}{5}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Basics Concepts in Neural Networks}{6}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2} Recurrent Neural Networks (RNNs)}{7}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3} Long-Short Term Memory (LSTM)}{8}{subsection.1.3.3}%
\contentsline {section}{\numberline {1.4} Transformer Architecture}{9}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Encoder and Decoder Stacks}{9}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Self-Attention Mechanism in Transformers}{11}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}Positional Encoding:}{11}{subsection.1.4.3}%
\contentsline {subsection}{\numberline {1.4.4}Role of Multi-Head Attention}{12}{subsection.1.4.4}%
\contentsline {subsection}{\numberline {1.4.5}The Rise of Transformers in Natural Language Processing}{12}{subsection.1.4.5}%
\contentsline {section}{\numberline {1.5} Emergence of Large Language Models (LLMs)}{12}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Scaling in Large Language Models (LLMs)}{13}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}Pre-training}{13}{subsection.1.5.2}%
\contentsline {subsection}{\numberline {1.5.3}Fine-tuning }{14}{subsection.1.5.3}%
\contentsline {subsection}{\numberline {1.5.4}Few-Shot, One-Shot, and Zero-Shot Learning}{15}{subsection.1.5.4}%
\contentsline {subsection}{\numberline {1.5.5}Evaluation Datasets and Tasks}{15}{subsection.1.5.5}%
\contentsline {section}{\numberline {1.6}Popular Models}{16}{section.1.6}%
\contentsline {subsection}{\numberline {1.6.1}GPT-N Models}{16}{subsection.1.6.1}%
\contentsline {subsection}{\numberline {1.6.2}BERT}{17}{subsection.1.6.2}%
\contentsline {subsection}{\numberline {1.6.3}T5}{17}{subsection.1.6.3}%
\contentsline {subsection}{\numberline {1.6.4}LLAMA2}{17}{subsection.1.6.4}%
\contentsline {subsection}{\numberline {1.6.5}Jais}{18}{subsection.1.6.5}%
\contentsline {section}{\numberline {1.7}Limitations of Large Language Models}{18}{section.1.7}%
\contentsline {subsection}{\numberline {1.7.1} Computational Cost}{18}{subsection.1.7.1}%
\contentsline {subsection}{\numberline {1.7.2}Bias and Ethical Concerns}{19}{subsection.1.7.2}%
\contentsline {subsection}{\numberline {1.7.3} Hallucinations}{19}{subsection.1.7.3}%
\contentsline {subsection}{\numberline {1.7.4}Overfitting}{19}{subsection.1.7.4}%
\contentsline {section}{\numberline {1.8}Domains of Application}{19}{section.1.8}%
\contentsline {subsection}{\numberline {1.8.1}Legal Information and Law}{20}{subsection.1.8.1}%
\contentsline {subsection}{\numberline {1.8.2}Cybersecurity}{20}{subsection.1.8.2}%
\contentsline {subsection}{\numberline {1.8.3}Medicine}{20}{subsection.1.8.3}%
\contentsline {subsection}{\numberline {1.8.4}journalism}{21}{subsection.1.8.4}%
\contentsline {section}{\numberline {1.9}Conclusion}{21}{section.1.9}%
\contentsline {chapter}{\numberline {2}Retrieval-Augmented Generation (RAG)}{22}{chapter.2}%
\contentsline {section}{\numberline {2.1}Introduction}{22}{section.2.1}%
\contentsline {section}{\numberline {2.2}Fundamentals of Retrieval-Augmented Generation}{22}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Definition of (RAG)}{22}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Historical Development of (RAG)}{23}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Differences between (RAG), fine-tuning and transfer learning}{23}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Types of (RAG) Systems}{24}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Naive (RAG)}{24}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Advanced (RAG)}{25}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Modular (RAG)}{26}{subsection.2.3.3}%
\contentsline {section}{\numberline {2.4}Core Components of RAG}{27}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1} Retrieval Mechanism}{27}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Generation Process}{28}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3} Augmentation Techniques}{29}{subsection.2.4.3}%
\contentsline {section}{\numberline {2.5}RAG for Legal Information Retrieval}{29}{section.2.5}%
\contentsline {section}{\numberline {2.6}Task and Evaluation}{30}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Factuality}{30}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2} Robustness}{30}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}Fairness}{31}{subsection.2.6.3}%
\contentsline {subsection}{\numberline {2.6.4}Objective Metrics:}{31}{subsection.2.6.4}%
\contentsline {subsection}{\numberline {2.6.5}Subjective Metrics}{31}{subsection.2.6.5}%
\contentsline {section}{\numberline {2.7} Challenges and Limitations in (RAG)}{31}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Scalability and Efficiency}{31}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Noisy Retrieval Results}{32}{subsection.2.7.2}%
\contentsline {subsection}{\numberline {2.7.3}Bias and Fairness}{32}{subsection.2.7.3}%
\contentsline {subsection}{\numberline {2.7.4}Extra Overhead}{32}{subsection.2.7.4}%
\contentsline {subsection}{\numberline {2.7.5}Long Context Generation:}{32}{subsection.2.7.5}%
\contentsline {section}{\numberline {2.8}Conclusion}{33}{section.2.8}%
\contentsline {chapter}{\numberline {3}k Selection in Retrieval}{34}{chapter.3}%
\contentsline {section}{\numberline {3.1}Introduction}{34}{section.3.1}%
\contentsline {section}{\numberline {3.2}Defining k: The Number of Retrieved Documents}{34}{section.3.2}%
\contentsline {section}{\numberline {3.3}Impact of k on Retrieval Performance}{35}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Recall vs. Precision}{35}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Retrieval Speed and Computational Cost}{36}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Document Ranking Quality}{37}{subsection.3.3.3}%
\contentsline {section}{\numberline {3.4}Impact of k on Generation Quality}{38}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Trade-off Between Diversity and Relevance}{38}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Effect on Text Generation Models}{39}{subsection.3.4.2}%
\contentsline {section}{\numberline {3.5}Existing Solutions for k Selection}{39}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Static k Selection}{39}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Dynamic k Selection}{40}{subsection.3.5.2}%
\contentsline {subsection}{\numberline {3.5.3}Hybrid k Selection}{40}{subsection.3.5.3}%
\contentsline {section}{\numberline {3.6} Proposed Solution}{41}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}Mixture of Logits (MoL)}{41}{subsection.3.6.1}%
\contentsline {subsection}{\numberline {3.6.2}Algorithm Design}{42}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Pseudocode}{44}{subsection.3.6.3}%
\contentsline {section}{\numberline {3.7}Recommendation System Overview}{45}{section.3.7}%
\contentsline {subsection}{\numberline {3.7.1}SASRec: Self-Attentive Sequential Recommendation}{45}{subsection.3.7.1}%
\contentsline {subsection}{\numberline {3.7.2}SASRec Model Architecture}{45}{subsection.3.7.2}%
\contentsline {section}{\numberline {3.8}Evaluation Metrics}{46}{section.3.8}%
\contentsline {section}{\numberline {3.9} Conclusion }{47}{section.3.9}%
\contentsline {chapter}{\numberline {4}Experimental Results}{48}{chapter.4}%
\contentsline {section}{\numberline {4.1}Introduction}{48}{section.4.1}%
\contentsline {section}{\numberline {4.2}Experimental Results}{48}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Dataset}{48}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2} Setup }{48}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}Impact of Hyperparameters}{49}{subsection.4.2.3}%
\contentsline {subsection}{\numberline {4.2.4}Impact of Adaptive k-Variations on Model Performance}{51}{subsection.4.2.4}%
\contentsline {section}{\numberline {4.3}Conclusion}{52}{section.4.3}%
\contentsline {chapter}{Bibliography}{55}{chapter*.35}%
